#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

/*
 * 2D Grouped Convolutional layer.
 *
 * This implementation splits input and output channels into groups
 * and performs separate convolutions for each group.
 */
source("scripts/nn/layers/conv2d_builtin.dml") as conv2d

forward = function(matrix[double] X, matrix[double] W, matrix[double] b,
                   int C, int Hin, int Win, int Hf, int Wf,
                   int strideh, int stridew, int padh, int padw, int groups)
    return (matrix[double] out, int Hout, int Wout) {
  /*
   * Computes the forward pass for a 2D grouped convolutional layer.
   * 
   * Inputs:
   *  - X: Inputs, of shape (N, C*Hin*Win).
   *  - W: Weights, of shape (F, C/groups*Hf*Wf).
   *  - b: Biases, of shape (F, 1).
   *  - C: Number of input channels.
   *  - Hin: Input height.
   *  - Win: Input width.
   *  - Hf: Filter height.
   *  - Wf: Filter width.
   *  - strideh: Stride over height.
   *  - stridew: Stride over width.
   *  - padh: Padding for height.
   *  - padw: Padding for width.
   *  - groups: Number of groups for grouped convolution.
   *
   * Outputs:
   *  - out: Outputs, of shape (N, F*Hout*Wout).
   *  - Hout: Output height.
   *  - Wout: Output width.
   */
  N = nrow(X)
  F = nrow(W)
  
  # Check that dimensions are divisible by groups
  if (C %% groups != 0) {
    stop("Number of input channels must be divisible by groups")
  }
  if (F %% groups != 0) {
    stop("Number of output channels must be divisible by groups")
  }
  
  C_per_group = C / groups
  F_per_group = F / groups
  
  # Calculate output dimensions (same for all groups)
  Hout = as.integer(floor((Hin + 2*padh - Hf)/strideh + 1))
  Wout = as.integer(floor((Win + 2*padw - Wf)/stridew + 1))
  
  # Initialize output
  out = matrix(0, rows=N, cols=F*Hout*Wout)
  
  # Perform grouped convolution
  for (g in 1:groups) {
    # Calculate channel ranges for this group
    c_start = (g-1) * C_per_group + 1
    c_end = g * C_per_group
    f_start = (g-1) * F_per_group + 1
    f_end = g * F_per_group
    
    # Extract input channels for this group
    X_group = matrix(0, rows=N, cols=C_per_group*Hin*Win)
    for (n in 1:N) {
      for (c in 0:(C_per_group-1)) {
        src_start = ((c_start-1+c)*Hin*Win) + 1
        src_end = (c_start+c)*Hin*Win
        dst_start = (c*Hin*Win) + 1
        dst_end = (c+1)*Hin*Win
        X_group[n, dst_start:dst_end] = X[n, src_start:src_end]
      }
    }
    
    # Extract weights and biases for this group
    W_group = W[f_start:f_end, ]
    b_group = b[f_start:f_end, ]
    
    # Perform convolution for this group
    [out_group, Hout_g, Wout_g] = conv2d::forward(X_group, W_group, b_group,
                                                   C_per_group, Hin, Win, Hf, Wf,
                                                   strideh, stridew, padh, padw)
    
    # Place group output in correct position
    for (n in 1:N) {
      for (f in 0:(F_per_group-1)) {
        src_start = (f*Hout*Wout) + 1
        src_end = (f+1)*Hout*Wout
        dst_start = ((f_start-1+f)*Hout*Wout) + 1
        dst_end = (f_start+f)*Hout*Wout
        out[n, dst_start:dst_end] = out_group[n, src_start:src_end]
      }
    }
  }
}

backward = function(matrix[double] dout, int Hout, int Wout,
                    matrix[double] X, matrix[double] W, matrix[double] b,
                    int C, int Hin, int Win, int Hf, int Wf,
                    int strideh, int stridew, int padh, int padw, int groups)
    return (matrix[double] dX, matrix[double] dW, matrix[double] db) {
  /*
   * Computes the backward pass for a 2D grouped convolutional layer.
   */
  N = nrow(X)
  F = nrow(W)
  
  C_per_group = C / groups
  F_per_group = F / groups
  
  # Initialize gradients
  dX = matrix(0, rows=N, cols=C*Hin*Win)
  dW = matrix(0, rows=F, cols=ncol(W))
  db = matrix(0, rows=F, cols=1)
  
  # Perform grouped backward pass
  for (g in 1:groups) {
    # Calculate channel ranges for this group
    c_start = (g-1) * C_per_group + 1
    c_end = g * C_per_group
    f_start = (g-1) * F_per_group + 1
    f_end = g * F_per_group
    
    # Extract gradients for this group
    dout_group = matrix(0, rows=N, cols=F_per_group*Hout*Wout)
    for (n in 1:N) {
      for (f in 0:(F_per_group-1)) {
        src_start = ((f_start-1+f)*Hout*Wout) + 1
        src_end = (f_start+f)*Hout*Wout
        dst_start = (f*Hout*Wout) + 1
        dst_end = (f+1)*Hout*Wout
        dout_group[n, dst_start:dst_end] = dout[n, src_start:src_end]
      }
    }
    
    # Extract input for this group
    X_group = matrix(0, rows=N, cols=C_per_group*Hin*Win)
    for (n in 1:N) {
      for (c in 0:(C_per_group-1)) {
        src_start = ((c_start-1+c)*Hin*Win) + 1
        src_end = (c_start+c)*Hin*Win
        dst_start = (c*Hin*Win) + 1
        dst_end = (c+1)*Hin*Win
        X_group[n, dst_start:dst_end] = X[n, src_start:src_end]
      }
    }
    
    # Extract weights for this group
    W_group = W[f_start:f_end, ]
    b_group = b[f_start:f_end, ]
    
    # Perform backward pass for this group
    [dX_group, dW_group, db_group] = conv2d::backward(dout_group, Hout, Wout,
                                                       X_group, W_group, b_group,
                                                       C_per_group, Hin, Win, Hf, Wf,
                                                       strideh, stridew, padh, padw)
    
    # Accumulate gradients
    for (n in 1:N) {
      for (c in 0:(C_per_group-1)) {
        src_start = (c*Hin*Win) + 1
        src_end = (c+1)*Hin*Win
        dst_start = ((c_start-1+c)*Hin*Win) + 1
        dst_end = (c_start+c)*Hin*Win
        dX[n, dst_start:dst_end] = dX_group[n, src_start:src_end]
      }
    }
    
    dW[f_start:f_end, ] = dW_group
    db[f_start:f_end, ] = db_group
  }
}

init = function(int F, int C, int Hf, int Wf, int groups, int seed = -1)
    return (matrix[double] W, matrix[double] b) {
  /*
   * Initialize the parameters of a grouped convolutional layer.
   *
   * Inputs:
   *  - F: Number of filters (output channels).
   *  - C: Number of input channels.
   *  - Hf: Filter height.
   *  - Wf: Filter width.
   *  - groups: Number of groups.
   *  - seed: Random seed (default: -1, random initialization).
   *
   * Outputs:
   *  - W: Weights, of shape (F, C/groups*Hf*Wf).
   *  - b: Biases, of shape (F, 1).
   */
  if (C %% groups != 0) {
    stop("Number of input channels must be divisible by groups")
  }
  if (F %% groups != 0) {
    stop("Number of output channels must be divisible by groups")
  }
  
  C_per_group = C / groups
  
  # Use Xavier initialization
  fan_in = C_per_group * Hf * Wf
  fan_out = F / groups * Hf * Wf
  scale = sqrt(6.0 / (fan_in + fan_out))
  
  if (seed != -1) {
    W = rand(rows=F, cols=C_per_group*Hf*Wf, min=-scale, max=scale, seed=seed)
  } else {
    W = rand(rows=F, cols=C_per_group*Hf*Wf, min=-scale, max=scale)
  }
  
  b = matrix(0, rows=F, cols=1)
}