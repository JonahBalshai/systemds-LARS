#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

/*
 * Small-scale test of ResNet-18 with LARS optimizer
 * 
 * This test uses smaller images and fewer samples to avoid memory issues
 * while still demonstrating LARS functionality.
 */

source("scripts/nn/examples/imagenet_resnet.dml") as resnet

print("ResNet-18 with LARS: Small-scale Test")
print("=====================================")

# Use smaller images to reduce memory usage
C = 3          # RGB channels
H = 32         # Reduced from 224
W = 32         # Reduced from 224
num_classes = 10  # Reduced from 1000

# Small dataset
N_train = 100   # Very small for testing
N_val = 20

# Generate small synthetic data
print("\nGenerating small synthetic data...")
X_train = rand(rows=N_train, cols=C*H*W, pdf="normal", seed=42) * 0.1
y_train = table(seq(1, N_train), sample(num_classes, N_train, TRUE), N_train, num_classes)

X_val = rand(rows=N_val, cols=C*H*W, pdf="normal", seed=43) * 0.1
y_val = table(seq(1, N_val), sample(num_classes, N_val, TRUE), N_val, num_classes)

print("Training data shape: " + nrow(X_train) + " x " + ncol(X_train))
print("Validation data shape: " + nrow(X_val) + " x " + ncol(X_val))

# Test parameters
epochs = 2
batch_size = 20
base_lr = 0.01

# Test 1: SGD with Momentum
print("\n\n--- Testing SGD with Momentum ---")
[model_sgd, emas_sgd] = resnet::train(X_train, y_train, X_val, y_val,
                                      C, H, W, epochs, "sgd_momentum", 
                                      base_lr, batch_size)

[loss_sgd, acc1_sgd, acc5_sgd] = resnet::evaluate(X_val, y_val, C, H, W, 
                                                   model_sgd, emas_sgd)
print("SGD Results - Loss: " + loss_sgd + ", Top-1: " + acc1_sgd + "%, Top-5: " + acc5_sgd + "%")

# Test 2: LARS
print("\n\n--- Testing LARS ---")
[model_lars, emas_lars] = resnet::train(X_train, y_train, X_val, y_val,
                                        C, H, W, epochs, "lars", 
                                        base_lr, batch_size)

[loss_lars, acc1_lars, acc5_lars] = resnet::evaluate(X_val, y_val, C, H, W,
                                                      model_lars, emas_lars)
print("LARS Results - Loss: " + loss_lars + ", Top-1: " + acc1_lars + "%, Top-5: " + acc5_lars + "%")

print("\n\nTest completed successfully!")
print("Note: This is a small-scale test. Results may not be meaningful due to:")
print("- Very small dataset size")
print("- Reduced image dimensions")
print("- Only 2 epochs of training")
print("\nFor real experiments, use the full Example-ImageNet_ResNet_LARS.dml with more memory.") 